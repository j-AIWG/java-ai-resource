<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-genai/using-llms-in-code/frameworks/langchain4j/langchain4j-deepdive-with-code" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Langchain4j Deep Dive with Code | Java and AI</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://lizeraes.github.io/java-ai-resource/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://lizeraes.github.io/java-ai-resource/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://lizeraes.github.io/java-ai-resource/docs/genai/using-llms-in-code/frameworks/langchain4j/langchain4j-deepdive-with-code/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Langchain4j Deep Dive with Code | Java and AI"><meta data-rh="true" name="description" content="as published in JAVAPRO - 30 Years of Java Edition"><meta data-rh="true" property="og:description" content="as published in JAVAPRO - 30 Years of Java Edition"><link data-rh="true" rel="icon" href="/java-ai-resource/img/jAI.png"><link data-rh="true" rel="canonical" href="https://lizeraes.github.io/java-ai-resource/docs/genai/using-llms-in-code/frameworks/langchain4j/langchain4j-deepdive-with-code/"><link data-rh="true" rel="alternate" href="https://lizeraes.github.io/java-ai-resource/docs/genai/using-llms-in-code/frameworks/langchain4j/langchain4j-deepdive-with-code/" hreflang="en"><link data-rh="true" rel="alternate" href="https://lizeraes.github.io/java-ai-resource/docs/genai/using-llms-in-code/frameworks/langchain4j/langchain4j-deepdive-with-code/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"GenAI","item":"https://lizeraes.github.io/java-ai-resource/docs/genai/"},{"@type":"ListItem","position":2,"name":"Using LLMs in Code","item":"https://lizeraes.github.io/java-ai-resource/docs/genai/using-llms-in-code/"},{"@type":"ListItem","position":3,"name":"Frameworks","item":"https://lizeraes.github.io/java-ai-resource/docs/genai/using-llms-in-code/frameworks/"},{"@type":"ListItem","position":4,"name":"LangChain4j","item":"https://lizeraes.github.io/java-ai-resource/docs/genai/using-llms-in-code/frameworks/langchain4j/"},{"@type":"ListItem","position":5,"name":"Langchain4j Deep Dive with Code","item":"https://lizeraes.github.io/java-ai-resource/docs/genai/using-llms-in-code/frameworks/langchain4j/langchain4j-deepdive-with-code"}]}</script><link rel="stylesheet" href="/java-ai-resource/assets/css/styles.3c2b5d44.css">
<script src="/java-ai-resource/assets/js/runtime~main.9ddfd0ce.js" defer="defer"></script>
<script src="/java-ai-resource/assets/js/main.164f5477.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/java-ai-resource/img/jAI.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/langchain4j_logo.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/devops_mlops.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/basic_llm.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/multimodality.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/augmented_llm.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/duke_loom.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/prefect_date.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/20-functionality/memory.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/mcp_architecture.png"><link rel="preload" as="image" href="https://javapro.io/wp-content/uploads/2025/02/image-74.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/20-functionality/basic_rag.png"><link rel="preload" as="image" href="https://javapro.io/wp-content/uploads/2025/02/image-55.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/20-functionality/advanced_rag.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/basic_agent.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/shopping_state_machine.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/orchestrator_synthesizer.png"><link rel="preload" as="image" href="https://javapro.io/wp-content/uploads/2025/02/image-80.png"><link rel="preload" as="image" href="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/users_program.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/java-ai-resource/"><div class="navbar__logo"><img src="/java-ai-resource/img/jAI.png" alt="jAI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/java-ai-resource/img/jAI.png" alt="jAI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Java and AI</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/java-ai-resource/docs/full-sitemap/">Contents</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/java-ai-resource/docs/full-sitemap/">Full Site Map</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/java-ai-resource/docs/genai/">GenAI</a><button aria-label="Collapse sidebar category &#x27;GenAI&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/java-ai-resource/docs/genai/genai-basics/">GenAI Basics</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/java-ai-resource/docs/genai/all-about-models/">All About Models</a><button aria-label="Expand sidebar category &#x27;All About Models&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/java-ai-resource/docs/genai/using-llms-in-code/">Using LLMs in Code</a><button aria-label="Collapse sidebar category &#x27;Using LLMs in Code&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/java-ai-resource/docs/genai/using-llms-in-code/functionality/">Functionality</a><button aria-label="Expand sidebar category &#x27;Functionality&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/java-ai-resource/docs/genai/using-llms-in-code/frameworks/">Frameworks</a><button aria-label="Collapse sidebar category &#x27;Frameworks&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/java-ai-resource/docs/genai/using-llms-in-code/frameworks/langchain4j/">LangChain4j</a><button aria-label="Collapse sidebar category &#x27;LangChain4j&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/java-ai-resource/docs/genai/using-llms-in-code/frameworks/langchain4j/langchain4j-doc/">Langchain4j Documentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/java-ai-resource/docs/genai/using-llms-in-code/frameworks/langchain4j/langchain4j-deepdive-with-code/">Langchain4j Deep Dive with Code</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/java-ai-resource/docs/genai/using-llms-in-code/frameworks/springai/">SpringAI</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/java-ai-resource/docs/genai/inference/">Inference</a><button aria-label="Expand sidebar category &#x27;Inference&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/java-ai-resource/docs/ml/">Machine Learning</a><button aria-label="Expand sidebar category &#x27;Machine Learning&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/java-ai-resource/docs/agentic-ai/">Agentic AI</a><button aria-label="Expand sidebar category &#x27;Agentic AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/java-ai-resource/docs/ai-assisted-coding/">AI Assisted Coding</a><button aria-label="Expand sidebar category &#x27;AI Assisted Coding&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/java-ai-resource/docs/ethics/">Ethics, Law, Security</a><button aria-label="Expand sidebar category &#x27;Ethics, Law, Security&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/java-ai-resource/docs/domain-use-cases/">Domain Use Cases</a><button aria-label="Expand sidebar category &#x27;Domain Use Cases&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/java-ai-resource/docs/learning-paths/">Learning Paths</a><button aria-label="Expand sidebar category &#x27;Learning Paths&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/java-ai-resource/docs/contribute/">Contribute</a><button aria-label="Expand sidebar category &#x27;Contribute&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/java-ai-resource/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/java-ai-resource/docs/genai/"><span>GenAI</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/java-ai-resource/docs/genai/using-llms-in-code/"><span>Using LLMs in Code</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/java-ai-resource/docs/genai/using-llms-in-code/frameworks/"><span>Frameworks</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/java-ai-resource/docs/genai/using-llms-in-code/frameworks/langchain4j/"><span>LangChain4j</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Langchain4j Deep Dive with Code</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Langchain4j Deep Dive with Code</h1></header>
<p><em>as <a href="https://javapro.io/2025/04/23/build-ai-apps-and-agents-in-java-hands-on-with-langchain4j/" target="_blank" rel="noopener noreferrer">published in JAVAPRO</a> - 30 Years of Java Edition</em></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="table-of-contents">Table of Contents<a href="#table-of-contents" class="hash-link" aria-label="Direct link to Table of Contents" title="Direct link to Table of Contents">​</a></h2>
<ul>
<li><a href="#intro-to-langchain4j">Intro to LangChain4j</a></li>
<li><a href="#architecture-of-ai-powered-apps">Architecture of AI-Powered Apps</a>
<ul>
<li><a href="#basic-blocks">Basic Blocks</a></li>
<li><a href="#multimodality">Multimodality</a></li>
<li><a href="#architecture-of-augmented-llms">Architecture of Augmented LLMs</a></li>
</ul>
</li>
<li><a href="#hello-world-how-can-i-assist-you-today">Hello world, how can I assist you today?</a></li>
<li><a href="#using-models">Using Models</a>
<ul>
<li><a href="#language-models-and-their-parameters">Language Models and their parameters</a></li>
<li><a href="#image-models">Image Models</a></li>
<li><a href="#audio-models">Audio models</a></li>
</ul>
</li>
<li><a href="#message-roles">Message Roles</a></li>
<li><a href="#ai-services">AI Services</a>
<ul>
<li><a href="#input-parameters-and-structured-outputs">Input parameters and structured outputs</a></li>
</ul>
</li>
<li><a href="#memory">Memory</a>
<ul>
<li><a href="#few-shot-examples">Few Shot Examples</a></li>
</ul>
</li>
<li><a href="#tools">Tools</a>
<ul>
<li><a href="#human-as-a-tool">Human as a tool</a></li>
<li><a href="#mcp-servers">MCP servers</a></li>
</ul>
</li>
<li><a href="#rag">RAG</a></li>
<li><a href="#agentic-systems">Agentic Systems</a>
<ul>
<li><a href="#basic-agent-llm-calls-code">Basic Agent: LLM calls code</a></li>
<li><a href="#state-machine-code-calls-llm-calls-code">State Machine: Code calls LLM calls code</a></li>
<li><a href="#combinations">Combinations</a></li>
</ul>
</li>
<li><a href="#production-features">Production Features</a></li>
<li><a href="#important-links">Important links</a></li>
<li><a href="#thank-you-and-faq">Thank you and FAQ</a></li>
</ul>
<p>LangChain4j is a java library to make <strong>interactions with AI models and LLMs in Java</strong> easy, with unified APIs that wrap different models. It also provides tools to let you build more <strong>complex use cases on top of basic functionality</strong>. At this 2nd anniversary of LangChain4j, we are thrilled to give you a walkthrough of the functionality that enables you to build basic and advanced AI-powered apps in Java.</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/langchain4j_logo.png" alt="LangChain4j Logo" style="width:50%;display:block;margin:auto">
<br>
<p>The goal of this article is to show you the most important features of LangChain4j, starting from the basics, building up to more advanced and cooler examples. Are you curious how to use LLMs in Java but never tried it yourself? Read on, this article is for you! Did you already build some apps but you&#x27;re curious to learn more advanced features and use cases? Skip the first chapters and jump right to the topic of your fancy.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="intro-to-langchain4j">Intro to LangChain4j<a href="#intro-to-langchain4j" class="hash-link" aria-label="Direct link to Intro to LangChain4j" title="Direct link to Intro to LangChain4j">​</a></h2>
<p>LangChain4j is all about interacting with AI models. Using a model is called <strong>inference</strong>. We can stay in our DevOps space and interact with the model via API, without caring too much about all the details in the layer below. What LangChain4j it NOT about:</p>
<ul>
<li>needing to understand how AI Models work under the hood: we can leave that to the data scientists.</li>
<li>training or fine tuning models: if you want to do that, have a look at Tribuo for classic machine learning strategies like regression, or at DeepLearning4j for deep learning and neural networks.</li>
</ul>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/devops_mlops.png" alt="DevOPS vs MLOPS" style="width:50%;display:block;margin:auto">
<br>
<p>The main building blocks of LangChain4j are <strong>LLMs</strong>, but also <strong>image models</strong>, <strong>audio models</strong> and so called <strong>multi-modal models</strong> that do more than one of the aforementioned things at the same time (dealing with multiple kinds of input and output).</p>
<p>You can use vanilla LangChain4j, but we also have a smooth integration with <strong>Quarkus</strong> (see <a href="https://github.com/quarkiverse/quarkus-langchain4j" target="_blank" rel="noopener noreferrer">github.com/quarkiverse/quarkus-langchain4j</a>) and <strong>Spring Boot</strong> (see spring-boot-example in <a href="http://github.com/langchain4j/langchain4j-examples" target="_blank" rel="noopener noreferrer">github.com/langchain4j/langchain4j-examples</a>). Links to the relevant repositories can be found at the end of this article.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="architecture-of-ai-powered-apps">Architecture of AI-Powered Apps<a href="#architecture-of-ai-powered-apps" class="hash-link" aria-label="Direct link to Architecture of AI-Powered Apps" title="Direct link to Architecture of AI-Powered Apps">​</a></h2>
<p>Here we give a high-level overview of the components of LangChain4j. Later in the article we will dive in the details and the code for each of them.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-blocks">Basic Blocks<a href="#basic-blocks" class="hash-link" aria-label="Direct link to Basic Blocks" title="Direct link to Basic Blocks">​</a></h3>
<p><strong>AI Models and Large Language Models (LLM):</strong> LangChain4j was initially built for LLMs as basic blocks.</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/basic_llm.png" alt="DevOPS vs MLOPS" style="width:50%;display:block;margin:auto">
<br>
<p>The LLM itself is basically a huge calculation scheme that will take words in and produce an answer that (often sounds like it) makes sense. It’s not important to understand how LLMs work under the hood to use LangChain4j. It is good to know that models vary in quality and capabilities, closely correlated with the model size.</p>
<p><strong>Other model types:</strong> LangChain4j supports specific image and audio models, as well as multimodal models that combine multiple input and/or output types. It is also possible to plug in and invoke any type of AI model, for example from HuggingFace (kind of Github for open source models).</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/multimodality.png" alt="Multimodality in AI Models" style="width:50%;display:block;margin:auto">
<br>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="architecture-of-augmented-llms">Architecture of Augmented LLMs<a href="#architecture-of-augmented-llms" class="hash-link" aria-label="Direct link to Architecture of Augmented LLMs" title="Direct link to Architecture of Augmented LLMs">​</a></h3>
<p>An LLM can work with a number of surrounding blocks to extend its functionality, making it very easy to turn them into very versatile and slightly risky agents. LLMs can be enhanced with general <strong>behavioral instructions, memory, extra context from content retrievers</strong> and the possibility to <strong>call tools</strong> to help it execute certain tasks. In the schema you see these components, along with their high level LangChain4j interface.</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/augmented_llm.png" alt="Augmented LLM Architecture" style="width:50%;display:block;margin:auto">
<br>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hello-world-how-can-i-assist-you-today">Hello world, how can I assist you today?<a href="#hello-world-how-can-i-assist-you-today" class="hash-link" aria-label="Direct link to Hello world, how can I assist you today?" title="Direct link to Hello world, how can I assist you today?">​</a></h2>
<p>Now let’s build something! To make a call to a model you will need to obtain an <strong>API key</strong> for the service you want to use. In this example we will be using OpenAI, you can obtain a key there really easily. I recommend <strong>storing the key in the environment variables</strong> to avoid accidentally pushing it to Github. You can also temporarily use LangChain4j’s demo key, which we provide for free for demonstration purposes (does not support advanced functionality!)</p>
<p>We always import the <strong>langchain4j</strong> (core) functionality:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">&lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;artifactId&gt;langchain4j&lt;/artifactId&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;version&gt;1.0.0-beta1&lt;/version&gt;</span><br></span></code></pre></div></div>
<p>You also need to import a model provider. For the code examples we are using <code>&lt;artifactId&gt;**langchain4j-open-ai**&lt;/artifactId&gt;</code>, but you can easily use other model providers, for example <a href="https://mvnrepository.com/artifact/dev.langchain4j/langchain4j-anthropic" target="_blank" rel="noopener noreferrer"><strong>langchain4j-anthropic</strong></a> etc. Now we’re ready to code</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import dev.langchain4j.model.chat.ChatLanguageModel;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import dev.langchain4j.model.openai.OpenAiChatModel;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">String apiKey = System.getenv(&quot;OPENAI_API_KEY&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// or String apiKey = &quot;demo&quot;;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ChatLanguageModel model = OpenAiChatModel.builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .apiKey(apiKey)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .modelName(&quot;gpt-4o-mini&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   .build();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">String answer = model.chat(&quot;Say &#x27;Hello World&#x27;&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">System.out.println(answer);</span><br></span></code></pre></div></div>
<p>This will sometimes return “Hello World”, and sometimes something else. Welcome to nondeterministic programming!</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="using-models"><strong>Using Models</strong><a href="#using-models" class="hash-link" aria-label="Direct link to using-models" title="Direct link to using-models">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="language-models-and-their-parameters">Language Models and their parameters<a href="#language-models-and-their-parameters" class="hash-link" aria-label="Direct link to Language Models and their parameters" title="Direct link to Language Models and their parameters">​</a></h3>
<p>Above we’ve seen the most basic invocation of OpenAI’s (the <strong>provider</strong>) GPT4-0 mini (the <strong>model</strong>). We support many more <strong>commercial providers</strong> (where you need a key), such as Gemini, Azure OpenAI, Anthropic, Mistral, Amazon Bedrock, etc. </p>
<p>We also support running <strong>local models</strong>, via <strong>Ollama</strong> (this downloads OSS models for you and serves them on localhost) and <strong>JLama</strong> (inference directly in Java, leveraging VectorAPI). Some reasons to use local models include privacy, cost, and also just using llama2-uncensored 👼<br>
<!-- -->An overview of <strong>all supported model integrations</strong>: <a href="https://docs.langchain4j.dev/integrations/language-models/" target="_blank" rel="noopener noreferrer">docs.langchain4j.dev/integrations/language-models/</a></p>
<p>Each model comes with its own set of <strong>parameters</strong> that you can set to tweak its behavior. What parameters are available and what they do can be found on the model provider’s website. This is how you set some of them for the OpenAI example:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ChatLanguageModel model = OpenAiChatModel.builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .apiKey(ApiKeys.OPENAI_API_KEY)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .modelName(GPT_4_O_MINI)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .temperature(0.3)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .timeout(ofSeconds(60))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .logRequests(true)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .logResponses(true)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .build();</span><br></span></code></pre></div></div>
<p>As you can see it allows us to set a <strong>timeout</strong> and define if requests and responses will be logged (try this in combination with <strong>log level</strong> <code>debug</code> to see the real calls to OpenAI). Higher values for <strong>temperature</strong> make the model more creative, lower values result in a more deterministic result.</p>
<p>The former example (<code>model.generate(String)</code>) returns a <strong>synchronous</strong> answer which includes waiting and then receiving lots of text at the same time. Models can also answer in <strong>streaming mode</strong> and return token by token, which allows for a much nicer user experience in chat applications. <strong>Tokens</strong> are chunks of text that are typically a couple of characters long. They are the model’s minimal meaningful unit, but we don’t really need to care, except that model prices are typically expressed per token.</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">StreamingChatLanguageModel model = OpenAiStreamingChatModel.builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        .apiKey(System.getenv(&quot;OPENAI_API_KEY&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        .modelName(GPT_4_O_MINI)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        .build();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">String userMessage = &quot;Write a poem about NullPointers&quot;;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model.chat(userMessage, new StreamingChatResponseHandler() {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    @Override</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    public void onPartialResponse(String partialResponse) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        System.out.print(partialResponse);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    @Override</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    public void onCompleteResponse(ChatResponse completeResponse) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        System.out.println(&quot;\n\nDone streaming&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    @Override</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    public void onError(Throwable error) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        error.printStackTrace();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">});</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="image-models"><strong>Image Models</strong><a href="#image-models" class="hash-link" aria-label="Direct link to image-models" title="Direct link to image-models">​</a></h3>
<p>Image models generate images based on a text prompt. LangChain4j has integrations with <strong>Dall-E, Imagen</strong> and some more image models that you can find under <a href="https://docs.langchain4j.dev/category/image-models" target="_blank" rel="noopener noreferrer">docs.langchain4j.dev/category/image-models</a> .</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ImageModel model = OpenAiImageModel.builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                .apiKey(System.getenv(&quot;OPENAI_API_KEY&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                .modelName(DALL_E_3)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                .build();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Response&lt;Image&gt; response = model.generate(&quot;java duke with loom, virtual threads and cat &quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">System.out.println(response.content().url());</span><br></span></code></pre></div></div>
<p>If you prefer storing the image directly, you can set the following parameters on the ImageModel:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ImageModel model = OpenAiImageModel.builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .apiKey(System.getenv(&quot;OPENAI_API_KEY&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .modelName(DALL_E_3)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .quality(DALL_E_QUALITY_HD)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .persistTo(Paths.get(&quot;src/main/resources/result-images&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .build();</span><br></span></code></pre></div></div>
<p>The result (impossible to get the true Java Duke out of Dall-E 😢 )</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/duke_loom.png" alt="Java Duke with Loom and Virtual Threads" style="width:50%;display:block;margin:auto">
<br>
<p><em>Funny cats, wasting computational resources since the invention of the internet</em></p>
<p>Make sure the folder is created beforehand. Image generation is calculation intensive. Generation can take a while and costs much more than text generation, for example $0.02 for a Dall-E 2 image and $0.08 for Dall-E 3.</p>
<p>Keep in mind that image generation is typically subject to <strong>rate limits</strong> that depend on your payment options, so before you launch your app on a big scale, make sure your subscription can keep up.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="audio-models"><strong>Audio models</strong><a href="#audio-models" class="hash-link" aria-label="Direct link to audio-models" title="Direct link to audio-models">​</a></h3>
<p>LangChain4j supports <strong>speech-to-text</strong> conversion with <strong>Gemini</strong> (support for more models is coming). The input is a String of the audio file in base64 format. Gemini will typically take your audio instructions (like “<em>who created Java</em>” and immediately take action, by replying “<em>James Gosling</em>”). If instead you want to obtain a literal transcription of your audio, you can prompt it as in the code example below.</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ChatLanguageModel model = GoogleAiGeminiChatModel.builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .apiKey(System.getenv(&quot;GEMINI_TOKEN&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .modelName(&quot;gemini-1.5-flash-001&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .build();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ChatResponse response = model.chat(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       SystemMessage.from(&quot;repeat the text from the audio message&quot;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       new UserMessage(AudioContent.from(base64, &quot;audio/mp3&quot;)));</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">String message = response.aiMessage().text();</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="message-roles">Message Roles<a href="#message-roles" class="hash-link" aria-label="Direct link to Message Roles" title="Direct link to Message Roles">​</a></h2>
<p>Before we continue, we need to introduce some important implementations of LangChain4j’s <strong><code>ChatMessage</code></strong> API:</p>
<ul>
<li><strong><code>SystemMessage</code></strong>: a message that we can optionally set to give general instructions to a model that will apply for the entire conversation. Eg. “<em>You are a java programmer talking to a 3 year old</em> ”.</li>
<li><strong><code>UserMessage</code></strong>: the user input (query, prompt)</li>
<li><strong><code>AiMessage</code></strong>: the reply of the model</li>
</ul>
<p>They can be used like this:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">UserMessage userMessage = UserMessage.from(&quot;How can I program my cat to fetch sticks for me?&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">AiMessage firstAiMessage = model.chat(userMessage).aiMessage();</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ai-services">AI Services<a href="#ai-services" class="hash-link" aria-label="Direct link to AI Services" title="Direct link to AI Services">​</a></h2>
<p>Now we know how to perform basic interactions with models, I want to introduce you to a somewhat strange but very powerful concept in LangChain4j: AiServices, your companion for every problem. I introduce them early on because they make the <strong>syntax</strong> to plug in other components (memory, tools, …) much <strong>more concise</strong>.</p>
<p>AiServices consist of an <strong>interface</strong> that describes what you want to happen. After which you can use a <strong>builder to create the implementation</strong> for you, specifying what <strong>components</strong> you want to add to it (model, RAG, tools, …).</p>
<p>Some examples can explain this better than 1000 words. Here’s a basic AiService:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">interface Programmer {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   @SystemMessage(&quot;You are a java programmer talking to a 3 year old&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   String answer(String question);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p>The interface describes what we want: a <code>Programmer</code> object with one method: <code>answer(String)</code>. We specify a <code>SystemMessage</code> (this is optional).</p>
<ul>
<li>The input is a <code>String</code>, so LangChain4j will infer that this is the <code>UserMessage</code>.</li>
<li>The output is a <code>String</code>, so LangChain4j will automatically infer that this is the model output.</li>
</ul>
<p>Now we want to create and use such a <code>Programmer</code> object (in the code below, <code>model</code> is a <code>ChatLanguageModel</code> that we created beforehand).</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Programmer programmer = AiServices.create(Programmer.class, model);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">String answer = programmer.answer(&quot;How can I program my cat to fetch sticks for me? Be concise&quot;);</span><br></span></code></pre></div></div>
<p>Running this code will return something like (love this!):</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Oh, little coder! 🐱✨ You can’t *program* a cat like a computer, but you can *train* it! Just like Java has loops, training takes **repetition**! </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. **Give treat** 🍗 when kitty touches the stick. </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. **Move stick a little** ➡️ and give treat again! </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. **Throw stick** and reward when kitty brings it back! </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Like a while-loop: </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">`while(cat_fetches) { giveTreat(); }` </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">But remember, cats have their own &quot;Garbage Collector&quot;—they ignore stuff when bored! 😹</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="input-parameters-and-structured-outputs">Input parameters and structured outputs<a href="#input-parameters-and-structured-outputs" class="hash-link" aria-label="Direct link to Input parameters and structured outputs" title="Direct link to Input parameters and structured outputs">​</a></h3>
<p>Now starts the real fun! LangChain4j allows you to get <strong>java objects out of LLMs</strong> so you can just code on instead of parsing Strings all the time. Here are some examples of how to use these <strong>structured outputs</strong>, and what kind of combinations are possible in the input parameters with <code>@UserMessage</code> and <code>@SystemMessage</code>. <code>TextUtils</code>, our AiService, has 3 methods this time:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">interface TextUtils {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   @SystemMessage(&quot;You are a professional translator into {{language}}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   @UserMessage(&quot;Translate the following text: {{text}}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   String translate(@V(&quot;text&quot;) String text, @V(&quot;language&quot;) String language);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   @SystemMessage(&quot;Summarize the user messag in {{n}} bullet points. Provide only bullet points.&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   List&lt;String&gt; summarize(@UserMessage String text, @V(&quot;n&quot;) int n);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   @UserMessage(&quot;Extract date and time from {{it}}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   LocalDateTime extractDateTimeFrom(String text);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p>We create an instance, so we can actually use them:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">TextUtils utils = AiServices.create(TextUtils.class, model);</span><br></span></code></pre></div></div>
<p><code>translate()</code> will return a <code>String</code>, so the direct output of the model.</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">String translation = utils.translate(&quot;Hello, how are you?&quot;, &quot;italian&quot;);</span><br></span></code></pre></div></div>
<p><code>summarize()</code> will return a Java object <code>List&lt;String&gt;</code>.</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">String text = &quot;AI is a branch of computer science that aims to create machines that mimic human intelligence. E.g. recognizing patterns or making decisions or predictions.&quot;;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">List&lt;String&gt; bulletPoints = utils.summarize(text, 3);</span><br></span></code></pre></div></div>
<p><code>extractDateTimeFrom()</code> is my favorite, done with endless parsing of date formats (if you can live with something that is <em>mostly</em> right but not always!)</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">text = &quot;Three days before St. Valentine&#x27;s Day of 2024, &quot; +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       &quot;just 15 minutes shy of midnight, &quot; +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       &quot;Jane discovered Jim was more in love with his IDE than with her.&quot;;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LocalDateTime dateTime = utils.extractDateTimeFrom(text);</span><br></span></code></pre></div></div>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/prefect_date.png" alt="Prefect Date Example" style="width:50%;display:block;margin:auto">
<br>
<p>Good to know: you can also make them return a self-defined POJO 🔥 For example a Person object:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">static class Person {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   @Description(&quot;first name of a person&quot;) // optional description for LLM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   private String firstName;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   private String lastName;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   private LocalDate birthDate;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   }</span><br></span></code></pre></div></div>
<p>And an AiService to extract all Persons from text fragments (great for analyzing archives)</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">interface PersonExtractor {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   @UserMessage(&quot;Extract all different persons from the following text: {{it}}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   List&lt;Person&gt; extractPersonFrom(String text);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="memory">Memory<a href="#memory" class="hash-link" aria-label="Direct link to Memory" title="Direct link to Memory">​</a></h2>
<p>Models are <strong>stateless</strong>, so if you want them to remember what has been said before, you have to <strong>send the history along every time</strong>. Most models&#x27; APIs provide a way to pass older messages from the conversation. LangChain4j wraps all the different syntaxes under one interface: <code>**ChatMemory**</code>. This is what memory looks like when we send it to an LLM</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/20-functionality/memory.png" alt="Memory Management in LLMs" style="width:50%;display:block;margin:auto">
<br>
<p>In theory we could keep the whole conversation in the memory, but it is sent along with every request. Memory eats tokens, and at some point we hit the size of the <strong>context window</strong>, the maximal number of tokens that a model accepts as input (model dependent). So we will need a <strong>strategy to reduce the memory size</strong>. LangChain4j comes with 2 default implementations:</p>
<ul>
<li><code>**MessageWindowChatMemory**</code>, which will drop the oldest messages</li>
</ul>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ChatMemory chatMemory = MessageWindowChatMemory.withMaxMessages(10);</span><br></span></code></pre></div></div>
<ul>
<li>Or <code>**TokenWindowChatMemory**</code>, which will drop the oldest tokens</li>
</ul>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ChatMemory chatMemory = TokenWindowChatMemory.withMaxTokens(1000, new OpenAiTokenizer());</span><br></span></code></pre></div></div>
<p><code>ChatMemory</code> is an interface, so you can write any implementation that makes sense for you, for example a <code>**SummarizingChatMemory**</code> that will keep track of important context based on your use case.</p>
<p>A <code>ChatMemory</code> is basically a <strong>list of <code>ChatMessages</code></strong> (see before), and you can manually add the messages for every <code>UserMessage</code> you send and every <code>AiMessage</code> you receive back. But if you <strong>combine <code>ChatMemory</code> with an <code>AiService</code></strong>, LangChain4j will take care of updating the memory for you. For example</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Programmer programmer = AiServices.builder(Programmer.class)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .chatLanguageModel(model)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .chatMemory(chatMemory)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .build();</span><br></span></code></pre></div></div>
<p>If you want to test if the memory is functioning properly, tell the model your name and ask ‘<em>what is my name</em>’ as the next question.</p>
<p>In a real application you will typically want to maintain and persist a memory per user. LangChain4j provides <code>MemoryId</code> functionality for this</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">interface Programmer {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   String chat(@MemoryId int memoryId, @UserMessage String userMessage);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p>In our langchain4j-examples repo (see link at the end), in the folder <code>tutorials</code>, you find this example fully elaborated with the memory per user persisted to a database.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="few-shot-examples">Few Shot Examples<a href="#few-shot-examples" class="hash-link" aria-label="Direct link to Few Shot Examples" title="Direct link to Few Shot Examples">​</a></h3>
<p>Do you want your model to behave in a certain way, but it’s not listening very well to your prompts and instructions? A more powerful technique is to pretend that the LLM behaved in the correct way by providing a <strong>fake memory pre-filled with examples</strong>, like this (if you need help setting boundaries 😉)</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">fewShotHistory.add(UserMessage.from(&quot;My mom wants me to call every day.&quot;)); fewShotHistory.add(AiMessage.from(&quot;You&#x27;re not a podcast.&quot;));  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fewShotHistory.add(UserMessage.from(&quot;My partner always lets me do the laundry.&quot;)); </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fewShotHistory.add(AiMessage.from(&quot;Did their hands fall off?&quot;));  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fewShotHistory.add(UserMessage.from(&quot;Toddler is crying bcs he didn’t get the pink cup.&quot;)); </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fewShotHistory.add(AiMessage.from(&quot;Tragic. For them.&quot;));</span><br></span></code></pre></div></div>
<p>Now add this <code>fewShotHistory</code> as memory to your <code>AiService</code>, ask it anything and enjoy your boundary coach!</p>
<p>Until now the models have returned text, images and java objects. A lot of models have an extra capability that makes them really powerful (and dangerous): calling your code. Are you in camp 🥳 or camp 😱 ?</p>
<p>You can provide a <strong>method that a model can call</strong>, such as sending an email, calculating interest or writing something to the database. Models that support <strong>function calling (tool calling)</strong> will reply with a function call including method name and parameter values when they think the question requires using the tool. We will run the called method and send the result back to the model, which will use the answer in its final reply.</p>
<p>LangChain4j makes that super easy, by using the <strong><code>@Tool</code> annotation</strong> as follows (the tools are part of class <code>ShoppingTools</code> in this example)</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@Tool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public List&lt;String&gt; getProductList() {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// custom code to obtain the list</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">@Tool(&quot;returns product description, price and availability&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">public String getProductDetails(@P(&quot;5 digits product ID&quot;) int prodID) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// custom code to obtain the product details</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p>If we have a <code>ShoppingAssistant</code> interface declared with a method <code>giveProductSuggestion(String userMessage)</code>, we can make the tools available as follows</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">ShoppingAssistant shoppingAssistant = AiServices.builder(ShoppingAssistant.class)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .chatLanguageModel(model)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .tools(new ShoppingTools())</span><br></span></code></pre></div></div>
<p>If we now run </p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">shoppingAssistant.giveProductSuggestion(&quot;I’m looking for a statue of Yoda that can sing Xmas songs&quot;); </span><br></span></code></pre></div></div>
<p>the model will (in most of the cases) call <code>getProductList()</code>, see if there’s anything in there that seems to match my request, and if yes, it will call <code>getProductDetails()</code> with the <code>productID</code> that it got as a result from <code>getProductList()</code>.<br>
<!-- -->It will then use all that information to craft a reply, like <em>“It seems like we don’t have a Yoda statue that sings Christmas songs, but I did find a singing Christmas goat in our catalog for 15.99$”</em>.</p>
<p>Good models are able to <strong>call tools sequentially and in parallel</strong>. In the example, it will first ask for the product list, and only then get specific product details. If it finds multiple singing Yoda’s that might carry my fancy, it will then call <code>getProductDetails</code> multiple times in parallel with the different product IDs.</p>
<p>Model calls and its subsequent tool calls are often <strong>high latency</strong>, so virtual threads come in handy to free resources while waiting for results.</p>
<p>Good to know: tools don’t work with all models, you can find the supported ones in the model integration list (<a href="https://docs.langchain4j.dev/integrations/language-models/" target="_blank" rel="noopener noreferrer">docs.langchain4j.dev/integrations/language-models</a>).</p>
<p>You can do a lot more things with tools: <strong>adding tools from different classes, specifying tools dynamically, returning the tool result as final answer</strong>, … you can find how to do all that in our documentation <a href="https://docs.langchain4j.dev/tutorials/tools/" target="_blank" rel="noopener noreferrer">docs.langchain4j.dev/tutorials/tools</a></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="human-as-a-tool">Human as a tool<a href="#human-as-a-tool" class="hash-link" aria-label="Direct link to Human as a tool" title="Direct link to Human as a tool">​</a></h3>
<p>LLMs executing tools, placing orders and accessing the database is dangerous. Depending on the <strong>risks or resources involved in executing a tool call</strong>, you may want to have some hard <strong>code checks</strong> in place (for example authentication) or ask the user for <strong>permission</strong> to proceed. The latter is called <strong>human-as-a-tool or human-in-the-loop</strong>, and can be obtained by adding a request for permission to run the tool as first thing in the tool code. If the answer is yes, the code continues, if no, you can throw an error back to the model that the user (or the verification code) did not allow the operation.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mcp-servers">MCP servers<a href="#mcp-servers" class="hash-link" aria-label="Direct link to MCP servers" title="Direct link to MCP servers">​</a></h3>
<p>If you’re anything like me, you’re probably hyperventilating by now and seeing all kinds of new automations that will make your life so much easier. Triage my emails, extract the TODOs, place them smartly in my agenda based on priorities and my existing calendar entries and and and… The new bottleneck for developers is <strong>writing all the tools</strong> that allow the LLM to execute these requests.</p>
<p>At the moment integrating with different services requires a different syntax and sometimes execution environment for almost anything you try to do. Github? git + ssh. Database? SQL + sqlplus. Local file system? Bash + terminal. Weather service? Custom REST API + curl. That’s a steep learning curve and quite hard to automate.</p>
<p>But the good news is, last November, Anthropic published the <strong>Model Context Protocol (MCP)</strong>, an open standard for <strong>exposing LLM-readable tools</strong>. The protocol got a lot of traction, and by now you can find hundreds of MCP servers on Github, just google ‘MCP server PostgreSQL’ (or Grafana, Github, Atlassian Gmail, … you name it). You can also <strong>create and publish your own MCP server</strong> really easily using Quarkus. Once you find a server, you can use it via LangChain4j’s integration like this:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">McpTransport transport = new StdioMcpTransport.Builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .command(List.of(&quot;/usr/local/bin/docker&quot;, &quot;run&quot;, &quot;-e&quot;, &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;, &quot;-i&quot;, &quot;mcp/github&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .logEvents(true)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .build();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">McpClient mcpClient = new DefaultMcpClient.Builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .transport(transport)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .build();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ToolProvider toolProvider = McpToolProvider.builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .mcpClients(List.of(mcpClient))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .build();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Bot bot = AiServices.builder(Bot.class)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .chatLanguageModel(model)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .toolProvider(toolProvider)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .build();</span><br></span></code></pre></div></div>
<p>You’ll typically need some <strong>API key to connect to services</strong> giving access to personal information, like <code>GITHUB_PERSONAL_ACCESS_TOKEN</code> in the example.<br>
<!-- -->This example uses <code>**stdio**</code> for communicating with your process. There are also servers that use <code>**http**</code>, see langchain4j-examples for the details.</p>
<p>The server exposes <strong>descriptions of available methods and parameters to the LLM</strong>. The server also takes care of <strong>translating parameters</strong> it is called with <strong>into the right syntax</strong>, and to <strong>execute</strong> the request, skipping all the difficulty of the previous diagram. The example above let&#x27;s an LLM create new branches and inspect PRs. Beautiful. Dangerous.</p>
<img src="/java-ai-resource/img/10-genai/mcp_architecture.png" alt="MCP Architecture" style="width:50%;display:block;margin:auto">
<br>
<p>Ease of integration with MCP servers</p>
<p>Important note: LLMs can be manipulated and unpredictable. Watch out before granting your LLM the rights to wipe your database or send emails autonomously!</p>
<p>Career tip: Developers may be at risk of losing their job to AI, but if you go into (LLM) security, you’re guaranteed to stay in demand 😅</p>
<img src="https://javapro.io/wp-content/uploads/2025/02/image-74.png" alt="MCP Architecture" style="width:50%;display:block;margin:auto">
<br>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rag">RAG<a href="#rag" class="hash-link" aria-label="Direct link to RAG" title="Direct link to RAG">​</a></h2>
<p>By now we can build really interesting LLM-powered apps. One last thing to address is that each model was <strong>trained on a specific dataset</strong>. We can’t hope for it to give us any information that was not present in its training data, such as the weather today, your company-specific procedures, your product database. In the best case it will say that it doesn’t know, in the worst (and more prevalent) case, it will hallucinate something that sounds plausible. So we need a way to let the model know about all that extra information that was not part of its training data.</p>
<p>One solution would be to ask our question and send all the available data along. It would probably work but you will pay a lot for all those tokens. If everything would fit in the context window in the first place. That is why we want to only pass the extra information to the model that is <strong>relevant</strong> to our question. This is called <strong>Retrieval-Augmented Generation (RAG)</strong> and this is how it looks schematically:</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/20-functionality/basic_rag.png" alt="Basic RAG Architecture" style="width:50%;display:block;margin:auto">
<br>
<p>Side note: if you think RAG is an ugly name, so do its creators. Quote Patrick Lewis: <em>&quot;We always planned to have a nicer sounding name, but when it was time to write the paper, no one had a better idea.&quot;</em></p>
<p>The relevant fragments of information, we need to search in the context that we offer to the model. LangChain4j has an interface <code>**ContentRetriever**</code> where you can implement your own retriever. We also provide the 4 most used ways out of the box (examples for each can be found under <code>/rag</code> in <code>langchain4j-examples</code>):</p>
<ul>
<li><strong>WebSearchEngineContentRetriever</strong>: the LLM turns the original prompt into a web search query and a number of search results are used as context</li>
<li><strong>SqlContentRetriever</strong>: the LLM is given the database schema and turns the original prompt into SQL to retrieve information that will be used as context</li>
<li><strong>Neo4jContentRetriever</strong>: the LLM is given the schema and turns the original prompt into Cypher (neo4j query) to retrieve information that will be used as context</li>
<li><strong>EmbeddingStoreContentRetriever</strong>: to retrieve relevant fragments from all documents that we provide (text, excel, images, audio, …). To find relevant fragments, we need to prepare our sources in advance in an <strong>ingestion step</strong>: We first <strong>chunk</strong> our sources into fragments, then we calculate a numerical <strong>vector representation (embedding)</strong> that encodes the meaning of each fragment (or image, table, …), using an <strong>embedding model</strong>. Finally, all embeddings are saved in an <code>**EmbeddingStore**</code> together with the original fragments. When the user asks a question, we will create an embedding of the question and <strong>retrieve</strong> the closest matches in our <code>EmbeddingStore</code>. This is called <strong>semantic similarity search</strong>.</li>
</ul>
<img src="https://javapro.io/wp-content/uploads/2025/02/image-55.png" alt="rag_schematic" style="width:80%;display:block;margin:auto">
<br>
<p>Lazy tip: In Quarkus, you can add an <code>EmbeddingStoreContentRetriever</code> to your <code>AiService</code> by simply adding the dependency <code>**quarkus-langchain4j-easy-rag**</code> and specifying <code>quarkus.langchain4j.easy-rag.path</code> in <code>application.properties</code>. This will use all documents stored in that folder as RAG sources.</p>
<p>Expert tip: Embeddings (vectors) can also be used to group topics or to find categories in data, by grouping the closest vectors together.</p>
<p>RAG works much better when we add some <strong>advanced RAG</strong> components around the <code>ContentRetriever</code> and its ContentInjector. Here are the available interfaces with their out-of-the-box implementations mentioned underneath:</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/20-functionality/advanced_rag.png" alt="Advanced RAG Architecture" style="width:50%;display:block;margin:auto">
<br>
<p>Advanced RAG (courtesy: Dmytro Liubarskyi)</p>
<ul>
<li><strong><code>QueryTransformers</code></strong>: they are very important to make RAG work properly. Imagine your RAG system has access to web search. The LLM asks you if you want to proceed with, say, the selected products. You say ‘yes please’, and off it goes searching the internet for ‘<em>yes please</em>’. You don’t want that, especially not in production. You will want a <strong><code>CompressingQueryTransformer</code></strong> that will take the rest of the conversation into account when forming its query, and turn ‘<em>yes please</em>’ in eg. ‘<em>proceed with selection of products: singing Yoda and Christmas goat</em>’. <strong><code>ExpandingQueryTransformer</code></strong> works similarly, but may create multiple queries to ensure an answer is found.</li>
<li>If you wish to use <strong>different <code>ContentRetrievers</code> in parallel</strong>, you can store them in a map, like this</li>
</ul>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Map&lt;ContentRetriever, String&gt; retrieverToDescription:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">literatureDocsRetriever -&gt; &quot;Scientific literature on antibodies&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">webSearchContentRetriever -&gt; &quot;Web search&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sequenceDbContentRetriever -&gt; &quot;Protein database with sequences&quot; </span><br></span></code></pre></div></div>
<ul>
<li>A <strong><code>QueryRouter</code></strong> will choose which <code>ContentRetriever(s)</code> the question should be sent to. You can write an own implementation, for example based on keywords, or use the <code>**LanguageModelQueryRouter**</code> that uses another LLM to route the question and transform it into queries for the different retriever types.</li>
<li><strong><code>ContentAggregator</code></strong>: the <strong><code>DefaultContentAggregator</code></strong> will simply put all selected fragments one after the other. However, very often (especially with <code>EmbeddingStoreContentRetriever</code>) fragments are found that are not related to the question and will only confuse the LLM if we send them along. You can use a <strong><code>ReRankingQueryTransformer</code></strong> to remove unrelated fragments. It uses a tiny and super fast scoring model specialized in scoring how relevant a piece of information is for a question.</li>
<li>The <strong><code>ContentInjector</code></strong> simply wraps your original message plus the extra fragments of content as follows:<br>
<code>&quot;{{userMessage}} \n\n &quot;Answer using the following information: \n {{contents}}&quot;</code><br>
<!-- -->If you want another message here or if you are using a different language, you can overwrite this as shown in the example below. The example also shows how all parts come together</li>
</ul>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">RetrievalAugmentor retrievalAugmentor = DefaultRetrievalAugmentor.builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .queryTransformer(queryTransformer)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .queryRouter(queryRouter)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .contentAggregator(contentAggregator)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .contentInjector(DefaultContentInjector.builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               .promptTemplate(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                       PromptTemplate.from(&quot;{{userMessage}}\n&quot; +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                               &quot;\n&quot; +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                               &quot;you can use the following information:\n&quot; +</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                               &quot;{{contents}}&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">               .build())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       .build();</span><br></span></code></pre></div></div>
<p>We can add this <code>RetrievalAugmentor</code> to our <code>Programmer</code> AiService like this</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">AiServices.builder(Programmer.class)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                       .chatLanguageModel(model)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                       .retrievalAugmentor(retrievalAugmentor)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                       .build();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<p>Good to know: In <strong>RAG</strong> everything happens in parallel and <strong>in one shot</strong>. This means it will fail for questions that require sequential searching like <em>‘find the sequence of an antigen of disease xyz’</em>, because it will need to find the antigen first before it can query the database for it’s sequence (that would be step 2). If you want to allow <strong>iterative searching</strong>, you can <strong>wrap your <code>ContentRetrievers</code> as <code>Tools</code></strong> and the model will know which ones to call in which order.</p>
<p>In <a href="http://github.com/langchain4j/langchain4j-examples/tree/main/rag-examples" target="_blank" rel="noopener noreferrer">github.com/langchain4j/langchain4j-examples/tree/main/rag-examples</a> you can find examples of all the above, as well as examples where <strong>sources</strong> are retrieved and passed along, and an example of the use of <strong>metadata</strong> stored with the fragments (to store read permissions or sources for example).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="agentic-systems">Agentic Systems<a href="#agentic-systems" class="hash-link" aria-label="Direct link to Agentic Systems" title="Direct link to Agentic Systems">​</a></h2>
<p>AI Agents is a very wide term that can cover anything from an LLM augmented with tools to a full-blown complex workflow system with multiple LLMs, orchestrators, workers, gatekeepers and sophisticated interactions with the environment.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-agent-llm-calls-code">Basic Agent: LLM calls code<a href="#basic-agent-llm-calls-code" class="hash-link" aria-label="Direct link to Basic Agent: LLM calls code" title="Direct link to Basic Agent: LLM calls code">​</a></h3>
<p>As a rule of thumb, <strong>build only the complexity that you need</strong>. For example, commercial LLMs can often perform quite complex tasks if you tell them the <strong>steps</strong> they need to run through, and the <strong>tools</strong> they need to use. If their tools include means to <strong>perform actions and observe the result</strong>, we have a basic AI Agent.</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/basic_agent.png" alt="Basic Agent Diagram" style="width:50%;display:block;margin:auto">
<br>
<p>Inspired by Anthropic agent architectures</p>
<p>As you can see, a LangChain4j <code>AiService</code> can easily do that, the programmatic difficulty lies mainly in creating good tools. MCP servers made that part a lot easier.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="state-machine-code-calls-llm-calls-code">State Machine: Code calls LLM calls code<a href="#state-machine-code-calls-llm-calls-code" class="hash-link" aria-label="Direct link to State Machine: Code calls LLM calls code" title="Direct link to State Machine: Code calls LLM calls code">​</a></h3>
<p>If you need more <strong>control over the workflow</strong>, you may consider structuring your process as a state machine, with the different <strong>steps (nodes)</strong> and <strong>transition criteria (edges)</strong> programmatically defined. The functionality inside of the <strong>nodes</strong> can be performed by <strong>AiServices</strong> (like determining which financial profile the customer has via guided chat) or nodes can be <strong>purely algorithmic</strong> (like running the calculations for the loan based on the financial profile – where using an LLM makes no sense).</p>
<p>The advantage here is more control and <strong>separation of concerns (and responsibilities)</strong> so LLMs don&#x27;t overstep their boundaries. It makes it much easier to <strong>add security checks</strong> and <strong>limit permissions</strong> for each node. It also allows us to outsource to code what better happens in code, and to pick <strong>tiny models for simple tasks</strong> and <strong>specialized models for specialized tasks</strong>. For example, for node transitions after a chat, you often get a situation like</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Model: Can you confirm your product selection?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">User: I still want to add a singing goat doll!</span><br></span></code></pre></div></div>
<p>To determine whether this means that you can move on to the next node (verify basket), or you stay in the current node a bit longer (select products), you can easily train a Bayesian classifier on 30 examples. It will do a great job and requires orders of magnitude less resources and latency.</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/shopping_state_machine.png" alt="Shopping State Machine" style="width:80%;display:block;margin:auto">
<br>
<p>It&#x27;s easier to program than it sounds: state machines are easy to code, and you can call AiServices in the nodes or on the edges, wherever it makes sense. Often you&#x27;ll also need an object to store the state, eg. the state of the shopping basket, the user profile, …</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="combinations">Combinations<a href="#combinations" class="hash-link" aria-label="Direct link to Combinations" title="Direct link to Combinations">​</a></h3>
<p>It gets really interesting when we wrap AiServices in tools. For example:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">@Tool</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">void determineFinancialProfile(){</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    FinancialProfileAiService.determineProfile(); // AiService </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // that has access to chat and tools </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // to complete a FinancialProfile object that keeps the state</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre></div></div>
<p>Now we can let another AiService, for example <code>BankChatBot</code> (the <strong>orchestrator</strong>) determine which other AiServices (wrapped in tools) to call. When the user asks the <code>BankChatBot</code> for a loan for example, the bot will know to call <code>determineFinancialProfile()</code> and <code>checkDebtRecords(String personID)</code>. That would be a variant of this architecture</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/orchestrator_synthesizer.png" alt="Orchestrator Synthesizer" style="width:80%;display:block;margin:auto">
<br>
<p>Inspired by Anthropic agent architectures</p>
<p>If the quality of the result is important, you can implement a pattern where a second LLM or AiService <strong>evaluates</strong> the first one:</p>
<img src="https://javapro.io/wp-content/uploads/2025/02/image-80.png" alt="Evaluator" style="width:50%;display:block;margin:auto">
<br>
<p>Inspired by Anthropic agent architectures</p>
<p>All these patterns are combinable, adaptable to your specific use case and surprisingly easy to program using <code>AiServices</code> and <code>Tools</code>. Where suitable tools can wrap other AiServices.</p>
<p>An important thing to keep in mind here is that model calls and tool calls introduce significant <strong>latency</strong>: depending on model and number of consumed/generated tokens it can be anything from 100s of milliseconds to 10s of seconds. So if your process allows it, keep the number of LLM calls low and use small (fast, cheap) specialized models.</p>
<p>Further reading: some more agentic architectures are covered in this article by Anthropic <a href="http://www.anthropic.com/research/building-effective-agents" target="_blank" rel="noopener noreferrer">www.anthropic.com/research/building-effective-agents</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="production-features">Production Features<a href="#production-features" class="hash-link" aria-label="Direct link to Production Features" title="Direct link to Production Features">​</a></h2>
<p>LLMs + production = nightmare? I feel you! But we can mitigate a lot with a number of more production-oriented features. In the second part of this JAVAPRO edition, we’ll get a whole article dedicated to those, but for the people that can’t wait, here are a couple of pointers to get you started (more details can be found online).</p>
<p><strong>Moderation</strong>: some models like <code>AzureOpenAI</code> come with built-in moderation that will check the model output for aspects like violence, so it allows you to filter out those responses.</p>
<p><strong>GuardRails</strong>: at the time of writing only available in <code>quarkus-langchain4j</code>, but coming soon to vanilla LangChain4j. <code>**InputGuardrails**</code> and <code>**OutputGuardrails**</code> are very powerful gatekeepers that will check if the prompt or the model input/output match certain criteria before sending it on. You can even use another LLM to do the check.</p>
<p><strong>Observability</strong>: <code>ChatModelListeners</code> allow you to observe things like <code>inputTokenCount</code> to calculate cost, or <code>finishReason</code> to keep statistics of failed calls.</p>
<p><strong>Testing non-deterministic apps:</strong> tests with retries come with <code>Junit Pioneer</code>, or even better (only in <code>quarkus-langchain4j</code> for now) <code>@QuarkusTest</code> allows you to give a score to your test output instead of having a clear pass vs. fail scenario. You can use scoring strategies like <code>AiJudgeStrategy</code> and <code>SemanticSimilarityStrategy</code> or create your own custom implementation.</p>
<p><strong>Human feedback:</strong> at my company Naboo.ai, we noticed that having all the above in place is still not sufficient to guarantee an excellent user experience. If, like us, you deal with user queries as input (&quot;_ask anything regarding your project and integrated tool_s&quot;), the variety of what users will ask beats anything you could have predicted upfront. It even beats what the overzealous testers could come up with!</p>
<img src="/java-ai-resource/img/10-genai/30-using-llms-in-code/30-frameworks/users_program.png" alt="User Programming Interface" style="width:50%;display:block;margin:auto">
<br>
<p>We solved this by collecting user feedback (thumbs up, or more important for us: thumbs down). If you want to offer a great user experience, consider a pilot phase where you manually review the creative caprices of your customers and extend your system to cover them. Once in production, you can continue gathering this feedback and use embeddings to find the most prevalent negative feedback categories and address those.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="important-links">Important links<a href="#important-links" class="hash-link" aria-label="Direct link to Important links" title="Direct link to Important links">​</a></h2>
<ul>
<li>LangChain4j repo: <a href="https://github.com/langchain4j/langchain4j" target="_blank" rel="noopener noreferrer">github.com/langchain4j/langchain4j</a></li>
<li>The dreaded but beautiful documentation (It doesn’t bite! It’s trying to be likeable with tutorials ♥️): <a href="https://docs.langchain4j.dev/" target="_blank" rel="noopener noreferrer">docs.langchain4j.dev</a></li>
<li>Community incubator repo for new integrations: <a href="https://github.com/langchain4j/langchain4j-community" target="_blank" rel="noopener noreferrer">github.com/langchain4j/langchain4j-community</a></li>
<li>Examples repo: <a href="https://github.com/langchain4j/langchain4j-examples" target="_blank" rel="noopener noreferrer">github.com/langchain4j/langchain4j-examples</a></li>
<li>Awesome LangChain4j examples: <a href="https://github.com/langchain4j/awesome-langchain4j" target="_blank" rel="noopener noreferrer">github.com/langchain4j/awesome-langchain4j</a></li>
<li>LangChain4j Discord: <a href="https://discord.com/invite/JzTFvyjG6R" target="_blank" rel="noopener noreferrer">discord.com/invite/JzTFvyjG6R</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="thank-you-and-faq">Thank you and FAQ<a href="#thank-you-and-faq" class="hash-link" aria-label="Direct link to Thank you and FAQ" title="Direct link to Thank you and FAQ">​</a></h2>
<ul>
<li>LangChain4j was <strong>created</strong> in 2023 by <strong>Dmytro Liubarskyi</strong>, who is still its relentless lead engineer. Thank you so much for your awesome work!</li>
<li><strong>Immense thanks to our 200+ contributors!</strong> Proudly listing the top 20 here, but everyone that didn’t make it to this list, we see you! Thank you Julien Dubois, Crutcher Dunnavant, Martin7-1, Konstantin Pavlov, jiangsier-xyz, Guillaume Laforge, Antonio Goncalves, Eddú Meléndez Gonzales, omarmahamid, Carlos Zela Bueno, Alexey Titov, Jan Martiska, xermaor, Georgios Andrianakis, kuraleta, bidek, Julien Perrochet, PrimosK, Eric Deandrea, Mario Fusco and all the other contributors ♥️</li>
<li><strong>LangChain4j</strong> is used <strong>in production</strong> in projects like MuleSoft by Salesforce, Advanced Coding Assistant by Deutsche Telekom, Apache Camel, MicroProfile, Wildfly, Micronaut and many more projects. We’re proud ^^</li>
<li><em><strong>Where are the chains in LangChain4j?</strong></em> Well erm, just like RAG, names are sticky… we abandoned the chains for the more versatile AiServices 🚀</li>
<li><strong><em>How do I contribute?</em></strong> You are very welcome to contribute! Bug fixes may not be the most glamorous thing, but they actually help us a ton and we appreciate it tremendously. For more tips and tricks, the contributor guide is linked in the readme.</li>
<li><em><strong>Aren’t the swag and the model licenses for testing expensive?</strong></em> Yes they are, so feel free to drop us some coins via <a href="http://opencollective.com/langchain4j" target="_blank" rel="noopener noreferrer">opencollective.com/langchain4j</a> for a swaggier future ☕🦜</li>
<li><em><strong>How much does it cost to use GPT4, or Gemini, or… ?</strong></em> Not that much, especially compared to the value they may bring to your product. Model pricing depends on the model quality (which you can assess using benchmarks, eg. <a href="http://www.livebench.ai/" target="_blank" rel="noopener noreferrer">www.livebench.ai</a>) and are calculated in function of input tokens (less expensive) and output tokens (more expensive). For a pricing overview, check llm-price.com. Tokens typically are about 3 characters long, so to give an idea, with <code>GPT4</code> you get around 12 A4 pages output for 1$, and for <code>claude-3.5-sonnet</code> that would be 48 pages for the same price.</li>
<li><em><strong>Just how good is a local model?</strong></em> It depends a lot on how much GPU you have available to run it on! For 700GB GPU you can run <code>deepseek-r1</code>, which performs in the top 5 of best models at the moment of writing, or <code>Llama-3.1-405B-Instruct</code> which performs in the top 30. But you will need specialized, expensive hardware. Models of around 70GB can run reasonably fast on a laptop, for example a Macbook Pro with enough unified memory (GPU+CPU) and still perform reasonably well. If you want to serve multiple users simultaneously, you need to do some research on the latency though. Then there are the really small models like Microsoft’s <code>phi3</code>, which is under 4GB. Some of those tiny models still perform very well for just language interaction with humans, but fail on more complex tasks and are very unreliable for tool calling.</li>
</ul>
<hr>
<p><em>Written by Lize Raes</em></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/10-genai/30-using-llms-in-code/30-frameworks/10-langchain4j/20-langchain4j-deepdive-with-code.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/java-ai-resource/docs/genai/using-llms-in-code/frameworks/langchain4j/langchain4j-doc/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Langchain4j Documentation</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/java-ai-resource/docs/genai/using-llms-in-code/frameworks/springai/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">SpringAI</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#table-of-contents" class="table-of-contents__link toc-highlight">Table of Contents</a></li><li><a href="#intro-to-langchain4j" class="table-of-contents__link toc-highlight">Intro to LangChain4j</a></li><li><a href="#architecture-of-ai-powered-apps" class="table-of-contents__link toc-highlight">Architecture of AI-Powered Apps</a><ul><li><a href="#basic-blocks" class="table-of-contents__link toc-highlight">Basic Blocks</a></li><li><a href="#architecture-of-augmented-llms" class="table-of-contents__link toc-highlight">Architecture of Augmented LLMs</a></li></ul></li><li><a href="#hello-world-how-can-i-assist-you-today" class="table-of-contents__link toc-highlight">Hello world, how can I assist you today?</a></li><li><a href="#using-models" class="table-of-contents__link toc-highlight"><strong>Using Models</strong></a><ul><li><a href="#language-models-and-their-parameters" class="table-of-contents__link toc-highlight">Language Models and their parameters</a></li><li><a href="#image-models" class="table-of-contents__link toc-highlight"><strong>Image Models</strong></a></li><li><a href="#audio-models" class="table-of-contents__link toc-highlight"><strong>Audio models</strong></a></li></ul></li><li><a href="#message-roles" class="table-of-contents__link toc-highlight">Message Roles</a></li><li><a href="#ai-services" class="table-of-contents__link toc-highlight">AI Services</a><ul><li><a href="#input-parameters-and-structured-outputs" class="table-of-contents__link toc-highlight">Input parameters and structured outputs</a></li></ul></li><li><a href="#memory" class="table-of-contents__link toc-highlight">Memory</a><ul><li><a href="#few-shot-examples" class="table-of-contents__link toc-highlight">Few Shot Examples</a></li><li><a href="#human-as-a-tool" class="table-of-contents__link toc-highlight">Human as a tool</a></li><li><a href="#mcp-servers" class="table-of-contents__link toc-highlight">MCP servers</a></li></ul></li><li><a href="#rag" class="table-of-contents__link toc-highlight">RAG</a></li><li><a href="#agentic-systems" class="table-of-contents__link toc-highlight">Agentic Systems</a><ul><li><a href="#basic-agent-llm-calls-code" class="table-of-contents__link toc-highlight">Basic Agent: LLM calls code</a></li><li><a href="#state-machine-code-calls-llm-calls-code" class="table-of-contents__link toc-highlight">State Machine: Code calls LLM calls code</a></li><li><a href="#combinations" class="table-of-contents__link toc-highlight">Combinations</a></li></ul></li><li><a href="#production-features" class="table-of-contents__link toc-highlight">Production Features</a></li><li><a href="#important-links" class="table-of-contents__link toc-highlight">Important links</a></li><li><a href="#thank-you-and-faq" class="table-of-contents__link toc-highlight">Thank you and FAQ</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/java-ai-resource/docs/intro/">Contents</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Java and AI Resource Hub. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>