"use strict";(self.webpackChunkdocusaurus_resource=self.webpackChunkdocusaurus_resource||[]).push([[3152],{28453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>l});var t=i(96540);const s={},o=t.createContext(s);function a(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(o.Provider,{value:n},e.children)}},91843:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>r,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"genai/using-llms-in-code/index","title":"Using LLMs in Code","description":"Quick Navigation","source":"@site/docs/10-genai/30-using-llms-in-code/index.md","sourceDirName":"10-genai/30-using-llms-in-code","slug":"/genai/using-llms-in-code/","permalink":"/java-ai-resource/docs/genai/using-llms-in-code/","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/10-genai/30-using-llms-in-code/index.md","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"title":"Using LLMs in Code","sidebar_position":10,"hide_title":true,"level":"beginner","status":"published","visibility":"public"},"sidebar":"tutorialSidebar","previous":{"title":"In-browser Models","permalink":"/java-ai-resource/docs/genai/all-about-models/model-providers/local/in-browser"},"next":{"title":"Functionality","permalink":"/java-ai-resource/docs/genai/using-llms-in-code/functionality/"}}');var s=i(74848),o=i(28453);const a={title:"Using LLMs in Code",sidebar_position:10,hide_title:!0,level:"beginner",status:"published",visibility:"public"},l="Using LLMs in Code",r={},c=[{value:"Quick Navigation",id:"quick-navigation",level:2},{value:"Chatting with Models",id:"chatting-with-models",level:2},{value:"Frameworks to the Rescue",id:"frameworks-to-the-rescue",level:2},{value:"Beyond Chat: Augmented LLMs",id:"beyond-chat-augmented-llms",level:2},{value:"From Augmented LLMs to Agents",id:"from-augmented-llms-to-agents",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"using-llms-in-code",children:"Using LLMs in Code"})}),"\n",(0,s.jsx)(n.h2,{id:"quick-navigation",children:"Quick Navigation"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#chatting-with-models",children:"Chatting with Models"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#frameworks-to-the-rescue",children:"Frameworks to the Rescue"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#beyond-chat-augmented-llms",children:"Beyond Chat: Augmented LLMs"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#from-augmented-llms-to-agents",children:"From Augmented LLMs to Agents"})}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:"Many people know how to use Large Language Models via applications like ChatGPT. But is also possible to talk directly to the underlying model (e.g., GPT-4) via API through code."}),"\n",(0,s.jsx)(n.p,{children:"This opens up very interesting use cases, from building a chatbot to your own flavor, up to creating agents that can manage your payments, orchestrate complex workflows, and control the lights in your house."}),"\n",(0,s.jsx)(n.h2,{id:"chatting-with-models",children:"Chatting with Models"}),"\n",(0,s.jsx)(n.p,{children:"In its simplest form, your code sends a request with a text message to the LLM in a syntax that's compatible with what it expects. For OpenAI models (the ones behind ChatGPT), it looks something like this:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'// Basic OpenAI API call\nPOST https://api.openai.com/v1/chat/completions\nAuthorization: Bearer your_openai_key\nContent-Type: application/json\n\n{\n    "model": "gpt-4",\n    "messages": [\n        {"role": "user", "content": "Hello, how are you?"}\n    ]\n}\n\n// Expected output: (this should be the Hi X, how can I assist you today)\n'})}),"\n",(0,s.jsx)(n.h2,{id:"frameworks-to-the-rescue",children:"Frameworks to the Rescue"}),"\n",(0,s.jsxs)(n.p,{children:["This raw API approach is quite verbose. Thankfully, there are frameworks available to make this much easier. For example, ",(0,s.jsx)(n.a,{href:"/docs/genai/using-llms-in-code/frameworks/langchain4j/",children:"LangChain4j"})," and ",(0,s.jsx)(n.a,{href:"/docs/genai/using-llms-in-code/frameworks/springai/",children:"SpringAI"})," make it as simple as:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'// LangChain4j example\nChatLanguageModel model = OpenAiChatModel.builder()\n    .apiKey("your_openai_key")\n    .modelName("gpt-4")\n    .build();\n\nString response = model.generate("Hello, how are you?");\n// Expected output: Hi! I\'m doing well, thank you for asking...\n\n// SpringAI example\n@Autowired\nprivate ChatClient chatClient;\n\nString response = chatClient.call("Hello, how are you?");\n// Expected output: Hi! I\'m doing well, thank you for asking...\n'})}),"\n",(0,s.jsx)(n.h2,{id:"beyond-chat-augmented-llms",children:"Beyond Chat: Augmented LLMs"}),"\n",(0,s.jsx)(n.p,{children:"Once we have code access to a model, we can do much more than just chatting. We can turn it into a so-called 'augmented LLM' that can:"}),"\n",(0,s.jsx)("img",{src:"/java-ai-resource/img/10-genai/30-using-llms-in-code/augmented_llm.png",alt:"Augmented LLM Architecture",style:{width:"50%",display:"block",margin:"auto"}}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Set instructions"})," to make the model behave a certain way"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Keep conversation memory"})," (or manipulate memory using few-shot approaches - see ",(0,s.jsx)(n.a,{href:"/docs/genai/using-llms-in-code/functionality/memory/",children:"Memory"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Retrieve information"})," from extra resources like your business documents or a weather forecast API (not just what the model was trained on)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Call your code"})," by telling it what methods are available (= ",(0,s.jsx)(n.a,{href:"/docs/genai/using-llms-in-code/functionality/tool-calling/",children:"tool calling"}),", also called function calling). Once the LLM can call your code, your code can call anything: robots, home equipment, you name it."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"from-augmented-llms-to-agents",children:"From Augmented LLMs to Agents"}),"\n",(0,s.jsxs)(n.p,{children:["Augmented LLMs that can 'act' this way start to behave like agents, specialized to solve specific tasks. You can combine agents to orchestrate bigger processes or plug them into deterministic workflows. More about that in the chapter on ",(0,s.jsx)(n.a,{href:"/docs/agentic-ai/",children:"Agentic AI"}),"."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Ready to dive in?"})," Check in more detail how things like ",(0,s.jsx)(n.a,{href:"/docs/genai/using-llms-in-code/functionality/memory/",children:"memory"}),", ",(0,s.jsx)(n.a,{href:"/docs/genai/using-llms-in-code/functionality/content-retrieval/",children:"RAG"})," and ",(0,s.jsx)(n.a,{href:"/docs/genai/using-llms-in-code/functionality/tool-calling/",children:"tool calling"})," work in ",(0,s.jsx)(n.a,{href:"/docs/genai/using-llms-in-code/functionality/",children:"functionality"})," or jump straight to your preferred ",(0,s.jsx)(n.a,{href:"/docs/genai/using-llms-in-code/frameworks/",children:"framework"}),"."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.em,{children:"Written by Lize Raes"})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);