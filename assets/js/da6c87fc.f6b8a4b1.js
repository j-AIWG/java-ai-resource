"use strict";(self.webpackChunkdocusaurus_resource=self.webpackChunkdocusaurus_resource||[]).push([[7957],{28453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(96540);const s={},o=t.createContext(s);function r(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(o.Provider,{value:n},e.children)}},52388:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"genai/using-llms-in-code/functionality/index","title":"Functionality","description":"LLMs basic function is to answer to questions or instructions. We can however, build a lot of interesting functionality around that to give them superpowers.","source":"@site/docs/10-genai/30-using-llms-in-code/20-functionality/index.md","sourceDirName":"10-genai/30-using-llms-in-code/20-functionality","slug":"/genai/using-llms-in-code/functionality/","permalink":"/java-ai-resource/docs/genai/using-llms-in-code/functionality/","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/10-genai/30-using-llms-in-code/20-functionality/index.md","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"title":"Functionality","sidebar_position":10,"hide_title":true,"level":"intermediate","status":"published","visibility":"public"},"sidebar":"tutorialSidebar","previous":{"title":"Using LLMs in Code","permalink":"/java-ai-resource/docs/genai/using-llms-in-code/"},"next":{"title":"Chatbots","permalink":"/java-ai-resource/docs/genai/using-llms-in-code/functionality/chatbots"}}');var s=i(74848),o=i(28453);const r={title:"Functionality",sidebar_position:10,hide_title:!0,level:"intermediate",status:"published",visibility:"public"},a="Functionality on Top of LLMs",l={},c=[];function u(e){const n={a:"a",em:"em",h1:"h1",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"functionality-on-top-of-llms",children:"Functionality on Top of LLMs"})}),"\n",(0,s.jsx)(n.p,{children:"LLMs basic function is to answer to questions or instructions. We can however, build a lot of interesting functionality around that to give them superpowers."}),"\n",(0,s.jsx)(n.p,{children:"In this chapter you'll find all the details on:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/java-ai-resource/docs/genai/using-llms-in-code/functionality/chatbots",children:"Chatbots"})})," - Build conversational interfaces"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/java-ai-resource/docs/genai/using-llms-in-code/functionality/memory",children:"Memory management"})})," - Keep context across conversations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"40-content-retrieval/",children:"Passing along extra context"})})," - Retrieval-Augmented Generation (RAG)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"30-tool-calling/",children:"Tool calling or function calling"})})," - Let LLMs call your code"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/java-ai-resource/docs/genai/using-llms-in-code/functionality/output-parsing",children:"Output parsing"})})," - Retrieve Java or JSON objects from the LLM instead of Strings"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/java-ai-resource/docs/genai/using-llms-in-code/functionality/guardrails",children:"Guardrails and moderation"})})," - Keep your augmented LLM in check"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"../../30-agentic-ai/",children:"Agentic behavior and orchestration"})})," - For complex workflows and agent systems"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["You'll end up with a super powerful LLM that in theory is capable of knowing everything and doing everything. An ",(0,s.jsx)(n.strong,{children:"augmented LLM"}),". Handle with care ;)"]}),"\n",(0,s.jsx)("img",{src:"/java-ai-resource/img/10-genai/30-using-llms-in-code/augmented_llm.png",alt:"Augmented LLM Architecture",style:{width:"50%",display:"block",margin:"auto"}}),"\n",(0,s.jsx)("br",{}),"\n",(0,s.jsx)(n.p,{children:"Unless you want to do very fancy and special things, use your favorite framework to make all of the above a breeze :)"}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.em,{children:"Written by Lize Raes"})})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}}}]);